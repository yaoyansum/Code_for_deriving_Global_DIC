{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a042a63f",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a33618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成：E:\\00DIC全球\\ERA5数据\\1984.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1985.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1986.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1987.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1988.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1989.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1990.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1991.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1992.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1993.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1994.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1995.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1996.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1997.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1998.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\1999.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2000.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2001.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2002.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2003.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2004.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2005.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2006.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2007.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2008.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2009.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2010.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2011.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2012.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2013.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2014.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2015.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2016.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2017.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2018.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2019.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2020.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2021.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2022.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2023.csv (包含11个属性)\n",
      "已生成：E:\\00DIC全球\\ERA5数据\\2024.csv (包含11个属性)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 参数设置\n",
    "# 设置输入和输出文件夹路径\n",
    "input_folder = r'E:\\00DIC全球\\ERA5数据'  # 替换为你的主文件夹路径\n",
    "output_folder = r'E:\\00DIC全球\\ERA5数据'    # 替换为输出文件夹路径\n",
    "year_range = range(1984, 2025)  # 包含1984-2024\n",
    "\n",
    "def process_data():\n",
    "    # 创建数据结构：{年份: {HYBAS_ID: {属性: 值}}}\n",
    "    year_dict = {year: {} for year in year_range}\n",
    "    \n",
    "    # 遍历所有CSV文件\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if not file.lower().endswith('.csv'):\n",
    "                continue\n",
    "            \n",
    "            # 从文件路径提取属性名（示例：用文件名作为属性）\n",
    "            attr_name = os.path.splitext(file)[0]  # 例如 \"温度.csv\" -> \"温度\"\n",
    "            \n",
    "            # 读取CSV数据\n",
    "            df = pd.read_csv(os.path.join(root, file))\n",
    "            hybas_ids = df.iloc[:, 0]  # 第一列为HYBAS_ID\n",
    "            \n",
    "            # 处理每个年份列\n",
    "            for year_col in df.columns[1:]:\n",
    "                try:\n",
    "                    year = int(year_col)\n",
    "                    if year not in year_range:\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    continue  # 跳过非年份列\n",
    "                \n",
    "                # 更新数据结构\n",
    "                for hybas_id, value in zip(hybas_ids, df[year_col]):\n",
    "                    if hybas_id not in year_dict[year]:\n",
    "                        year_dict[year][hybas_id] = {}\n",
    "                    year_dict[year][hybas_id][attr_name] = value\n",
    "\n",
    "    # 保存结果\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for year in year_range:\n",
    "        year_data = year_dict[year]\n",
    "        if not year_data:\n",
    "            continue\n",
    "        \n",
    "        # 转换为DataFrame\n",
    "        df = pd.DataFrame.from_dict(year_data, orient='index')\n",
    "        df.index.name = 'HYBAS_ID'\n",
    "        df.reset_index(inplace=True)\n",
    "        \n",
    "        # 保存CSV\n",
    "        output_path = os.path.join(output_folder, f\"{year}.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"已生成：{output_path} (包含{len(df.columns)-1}个属性)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efbcbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功加载固有属性文件，包含 16397 个唯一HYBAS_ID\n",
      "▏ 已处理 1984.csv → 1984.csv | 总记录数: 16397\n",
      "▏ 已处理 1985.csv → 1985.csv | 总记录数: 16397\n",
      "▏ 已处理 1986.csv → 1986.csv | 总记录数: 16397\n",
      "▏ 已处理 1987.csv → 1987.csv | 总记录数: 16397\n",
      "▏ 已处理 1988.csv → 1988.csv | 总记录数: 16397\n",
      "▏ 已处理 1989.csv → 1989.csv | 总记录数: 16397\n",
      "▏ 已处理 1990.csv → 1990.csv | 总记录数: 16397\n",
      "▏ 已处理 1991.csv → 1991.csv | 总记录数: 16397\n",
      "▏ 已处理 1992.csv → 1992.csv | 总记录数: 16397\n",
      "▏ 已处理 1993.csv → 1993.csv | 总记录数: 16397\n",
      "▏ 已处理 1994.csv → 1994.csv | 总记录数: 16397\n",
      "▏ 已处理 1995.csv → 1995.csv | 总记录数: 16397\n",
      "▏ 已处理 1996.csv → 1996.csv | 总记录数: 16397\n",
      "▏ 已处理 1997.csv → 1997.csv | 总记录数: 16397\n",
      "▏ 已处理 1998.csv → 1998.csv | 总记录数: 16397\n",
      "▏ 已处理 1999.csv → 1999.csv | 总记录数: 16397\n",
      "▏ 已处理 2000.csv → 2000.csv | 总记录数: 16397\n",
      "▏ 已处理 2001.csv → 2001.csv | 总记录数: 16397\n",
      "▏ 已处理 2002.csv → 2002.csv | 总记录数: 16397\n",
      "▏ 已处理 2003.csv → 2003.csv | 总记录数: 16397\n",
      "▏ 已处理 2004.csv → 2004.csv | 总记录数: 16397\n",
      "▏ 已处理 2005.csv → 2005.csv | 总记录数: 16397\n",
      "▏ 已处理 2006.csv → 2006.csv | 总记录数: 16397\n",
      "▏ 已处理 2007.csv → 2007.csv | 总记录数: 16397\n",
      "▏ 已处理 2008.csv → 2008.csv | 总记录数: 16397\n",
      "▏ 已处理 2009.csv → 2009.csv | 总记录数: 16397\n",
      "▏ 已处理 2010.csv → 2010.csv | 总记录数: 16397\n",
      "▏ 已处理 2011.csv → 2011.csv | 总记录数: 16397\n",
      "▏ 已处理 2012.csv → 2012.csv | 总记录数: 16397\n",
      "▏ 已处理 2013.csv → 2013.csv | 总记录数: 16397\n",
      "▏ 已处理 2014.csv → 2014.csv | 总记录数: 16397\n",
      "▏ 已处理 2015.csv → 2015.csv | 总记录数: 16397\n",
      "▏ 已处理 2016.csv → 2016.csv | 总记录数: 16397\n",
      "▏ 已处理 2017.csv → 2017.csv | 总记录数: 16397\n",
      "▏ 已处理 2018.csv → 2018.csv | 总记录数: 16397\n",
      "▏ 已处理 2019.csv → 2019.csv | 总记录数: 16397\n",
      "▏ 已处理 2020.csv → 2020.csv | 总记录数: 16397\n",
      "▏ 已处理 2021.csv → 2021.csv | 总记录数: 16397\n",
      "▏ 已处理 2022.csv → 2022.csv | 总记录数: 16397\n",
      "▏ 已处理 2023.csv → 2023.csv | 总记录数: 16397\n",
      "▏ 已处理 2024.csv → 2024.csv | 总记录数: 16397\n",
      "\n",
      "处理完成！成功合并 41/41 个文件\n",
      "输出目录：path/to/output_folder\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ======================\n",
    "# 配置参数\n",
    "# ======================\n",
    "annual_folder = r\"E:\\00DIC全球\\ERA5数据\\年均属性值\"  # 存储年度CSV的文件夹路径\n",
    "static_file = r\"E:\\00DIC全球\\ERA5数据\\HYBAS_DEM_Slope_Area_Export.csv\"  # 固有属性文件路径\n",
    "output_folder = \"path/to/output_folder\"  # 输出目录（可与输入目录相同）\n",
    "merge_suffix = \"\"  # 合并后文件名后缀（设为空字符串可覆盖原文件）\n",
    "\n",
    "# ======================\n",
    "# 函数定义\n",
    "# ======================\n",
    "def validate_static_data(static_df):\n",
    "    \"\"\"验证固有属性文件结构\"\"\"\n",
    "    if 'HYBAS_ID' not in static_df.columns:\n",
    "        raise ValueError(\"固有属性文件必须包含HYBAS_ID列\")\n",
    "    if static_df['HYBAS_ID'].duplicated().any():\n",
    "        raise ValueError(\"固有属性文件中存在重复的HYBAS_ID\")\n",
    "\n",
    "def merge_attributes(annual_file, static_df):\n",
    "    \"\"\"合并单个年度文件\"\"\"\n",
    "    # 读取年度文件\n",
    "    annual_path = os.path.join(annual_folder, annual_file)\n",
    "    df_annual = pd.read_csv(annual_path)\n",
    "    \n",
    "    # 检查HYBAS_ID列是否存在\n",
    "    if 'HYBAS_ID' not in df_annual.columns:\n",
    "        raise KeyError(f\"{annual_file} 中缺少HYBAS_ID列\")\n",
    "    \n",
    "    # 执行数据合并（左连接）\n",
    "    merged_df = pd.merge(\n",
    "        df_annual,\n",
    "        static_df,\n",
    "        on='HYBAS_ID',\n",
    "        how='left',  # 保留所有年度数据中的记录\n",
    "        validate='m:1'  # 确保静态数据中的HYBAS_ID唯一\n",
    "    )\n",
    "    \n",
    "    # 调整列顺序：静态属性在前\n",
    "    static_cols = [col for col in static_df.columns if col != 'HYBAS_ID']\n",
    "    ordered_cols = ['HYBAS_ID'] + static_cols + \\\n",
    "                  [col for col in merged_df.columns \n",
    "                   if col not in ['HYBAS_ID'] + static_cols]\n",
    "    \n",
    "    return merged_df[ordered_cols]\n",
    "\n",
    "# ======================\n",
    "# 主程序\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 创建输出目录\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        # 步骤1：加载并验证固有属性数据\n",
    "        static_df = pd.read_csv(static_file)\n",
    "        validate_static_data(static_df)\n",
    "        print(f\"✅ 成功加载固有属性文件，包含 {len(static_df)} 个唯一HYBAS_ID\")\n",
    "\n",
    "        # 步骤2：处理年度文件\n",
    "        processed = 0\n",
    "        annual_files = [f for f in os.listdir(annual_folder) if f.endswith('.csv')]\n",
    "        \n",
    "        for file in annual_files:\n",
    "            try:\n",
    "                # 执行合并操作\n",
    "                result_df = merge_attributes(file, static_df)\n",
    "                \n",
    "                # 生成输出文件名\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "                output_name = f\"{base_name}{merge_suffix}.csv\"\n",
    "                output_path = os.path.join(output_folder, output_name)\n",
    "                \n",
    "                # 保存结果\n",
    "                result_df.to_csv(output_path, index=False)\n",
    "                processed += 1\n",
    "                print(f\"▏ 已处理 {file} → {output_name} | 总记录数: {len(result_df)}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 处理 {file} 时出错: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # 输出统计信息\n",
    "        print(f\"\\n处理完成！成功合并 {processed}/{len(annual_files)} 个文件\")\n",
    "        print(f\"输出目录：{output_folder}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 程序运行失败: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b0258",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "171c5254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1985_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1986_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1987_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1988_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1989_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1990_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1991_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1992_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1993_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1994_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1995_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1996_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1997_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1998_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\1999_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2000_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2001_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2002_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2003_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2004_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2005_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2006_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2007_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2008_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2009_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2010_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2011_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2012_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2013_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2014_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2015_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2016_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2017_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2018_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2019_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2020_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2021_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2022_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2023_预测.csv\n",
      "预测结果已保存至：E:\\00DIC全球\\ERA5数据\\年均属性值\\2024_预测.csv\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# 从本地加载模型（使用原始字符串避免转义问题）\n",
    "pipeline = load(r'E:\\00DIC全球\\数据\\训练数据\\model_predictions_wtDEM.joblib')\n",
    "\n",
    "    # 数据加载\n",
    "for year in range(1985,2025):\n",
    "    # 修正f-string语法，使用原始字符串前缀\n",
    "    data = pd.read_csv(rf\"E:\\00DIC全球\\ERA5数据\\年均属性值\\{year}.csv\")\n",
    "    X = data.drop(\"HYBAS_ID\", axis=1)\n",
    "    ID = data[\"HYBAS_ID\"]\n",
    "\n",
    "    # 执行预测\n",
    "    predictions = pipeline.predict(X)\n",
    "\n",
    "    # 创建结果DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'HYBAS_ID': ID,\n",
    "        'Predicted': predictions\n",
    "    })\n",
    "\n",
    "    # 保存预测结果（改为直接保存CSV）\n",
    "    output_path = rf\"E:\\00DIC全球\\ERA5数据\\年均属性值\\{year}_预测.csv\"\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"预测结果已保存至：{output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c76572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn]",
   "language": "python",
   "name": "conda-env-sklearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
